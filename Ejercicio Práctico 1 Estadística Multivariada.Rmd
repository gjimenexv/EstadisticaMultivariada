---
title: "Ejercicio Práctico 1 Estadística Multivariada"
author: "Guillermo Jiménez, Fabian Barquero, Alexa Campos"
date: "`r Sys.Date()`"
output:
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(ggplot2)
library(readxl)
library(dplyr)
library(tidyr)

# Ejercicio Práctico 1
## Analisis de Clientes Bancarios
```

## Carga de Datos

# Pregunta 1: Analizando la relación entre variables

<p>Es importante entender que relaciones existent entre las variable cuantitativas y en este caso la hipotesis de salida del banco de algunos clientes. </p>
```{r pressure, echo=FALSE}
# SCarga de datos
datos <- read_excel("BankChurn.xlsx")
datos$Exited <- factor(datos$Exited, levels = c(0, 1), labels = c("Se Queda", "Abandona"))

# Preparación para graficado múltiple
datos_long <- datos %>%
  select(Exited, CreditScore, Age, Tenure, EstimatedSalary) %>%
  pivot_longer(cols = -Exited, names_to = "Variable", values_to = "Valor")

# Generación del gráfico
ggplot(datos_long, aes(x = Exited, y = Valor, fill = Exited)) +
  geom_boxplot(alpha = 0.7, outlier.color = "red") +
  facet_wrap(~Variable, scales = "free") +
  theme_minimal() +
  labs(title = "Distribución de Variables según Abandono",
       x = "Estado del Cliente",
       y = "Valor Observado") +
  scale_fill_manual(values = c("#3498db", "#e74c3c"))
```

<p>Como se puede apreciar la variable que mas diferencia prenseta cuando han salido los clientes es la de años. Teniendo una media un poco mas elevada para cuando ya salen. </p>

# Pregunta 2: Combianacion de variables Años y Antiguedad

## Análisis de Varianza de Variable Combinada

### A: Varianza individual

En estadística multivariada, cuando sumamos dos variables, la varianza del resultado NO es simplemente la suma de las varianzas individuales, a menos que las variables sean independientes.

Esto es por que la formula es clara, incluye la covariablidad entre ambas.

$$V(X_1 + X_2) = V(X_1) + V(X_2) + 2 \cdot Cov(X_1, X_2)$$

### B: Varianza 


```{r pregunta-2}
# 1. Crear la variable combinada
datos$Age_Tenure <- datos$Age + datos$Tenure

# 2. Calcular varianzas individuales
var_age <- var(datos$Age)
var_tenure <- var(datos$Tenure)

# 3. Calcular la covarianza entre ambas
cov_age_tenure <- cov(datos$Age, datos$Tenure)

# 4. Cálculo de varianza de la variable nueva (Directo)
var_combinada_real <- var(datos$Age_Tenure)

# 5. Cálculo teórico usando la fórmula
var_teorica <- var_age + var_tenure + (2 * cov_age_tenure)

# Mostramos los resultados para comparar
resultados <- data.frame(
  Metodo = c("Suma Simple (V1 + V2)", "Varianza Real (Nueva Variable)", "Cálculo Teórico (Fórmula)"),
  Valor = c(var_age + var_tenure, var_combinada_real, var_teorica)
)

print(resultados)

```


# Pregunta 3: Prueba de normalidad multivariada

## Análisis de Normalidad y Distorsión

```{r prueba-jb}
# 1. Cargar las librerías solicitadas
library(tseries) # Para jarque.bera.test
library(moments) # Para skewness y kurtosis
library(nortest) # Para pruebas de normalidad adicionales

# 2. Seleccionar variables
vars_cuant <- datos[, c("CreditScore", "Age", "Tenure", "EstimatedSalary")]

# 3. Aplicar Jarque-Bera y estadísticos de forma masiva
analisis_univariado <- sapply(vars_cuant, function(x) {
  test <- jarque.bera.test(x)
  c(Asimetria = skewness(x), 
    Curtosis_Exceso = kurtosis(x) - 3, # Restamos 3 para que 0 sea el ideal
    JB_p_value = test$p.value)
})

print(t(analisis_univariado))
```


**A. ¿Es razonable que la variable X se distribuya de manera normal? ¿Por qué?**

**La variable crítica es Age (Edad).** el valor de `Asimetria`para **Age**, es cercano a $1.01$. En una normal perfecta, debería ser $0$.

**CreditScore** también tiene una curtosis negativa, pero la edad es la que más se aleja del ideal de simetría.

# Pregunta 4: Prueba de vectores

## Prueba de Hipótesis Multivariada (Hotelling's T2)

```{r prueba-hotelling}
# 1. Cargar librerías
library(ICSNP) # Para la función HotellingsT2

# 2. Filtrar los datos: solo los que salieron del banco (Exited == 1)
datos_exit <- datos %>% 
  filter(Exited == "Abandona") %>% 
  select(CreditScore, Age, Tenure, EstimatedSalary)

# 3. Definir nuestro vector de "Creencia" (mu_0)
mu_0 <- c(650, 45, 5, 100000)

# 4. Realizar la prueba formal
prueba_t2 <- HotellingsT2(datos_exit, mu = mu_0)

print(prueba_t2)
```

Tras realizar la prueba de Hotelling, obtuvimos un p-value de 0.1311. Dado que este es mayor a 0.05, concluimos que no existe una diferencia significativa entre el comportamiento real de los clientes que abandonan y nuestra creencia teórica.


## Análisis Post-Hoc: Intervalos de Confianza Simultáneos

```{r intervalos-simultaneos}
# 1. Parámetros básicos
n <- nrow(datos_exit)
p <- ncol(datos_exit)
alfa <- 0.05

# 2. Valor crítico basado en la distribución F (Escalado para Hotelling)
valor_critico <- sqrt(((p * (n - 1)) / (n - p)) * qf(1 - alfa, p, n - p))

# 3. Medias y Desviaciones Estándar de la muestra
medias_reales <- colMeans(datos_exit)
desv_est <- sapply(datos_exit, sd)
error_estandar <- desv_est / sqrt(n)

# 4. Construcción de los intervalos
lim_inf <- medias_reales - (valor_critico * error_estandar)
lim_sup <- medias_reales + (valor_critico * error_estandar)

# 5. Comparación con nuestra "Creencia" (mu_0)
tabla_comparativa <- data.frame(
  Variable = names(medias_reales),
  Creencia = mu_0,
  Media_Real = medias_reales,
  Inf_95 = lim_inf,
  Sup_95 = lim_sup,
  Diferencia_Signif = ifelse(mu_0 < lim_inf | mu_0 > lim_sup, "SÍ", "NO")
)

print(tabla_comparativa)

```

## Pregunta 5: Comparación de Grupos (Se quedan vs Se van)

```{r comparacion-grupos}
# 1. Separar los datos en dos grupos
grupo_quedan <- datos %>% filter(Exited == "Se Queda") %>% 
                select(CreditScore, Age, Tenure, EstimatedSalary)
grupo_van <- datos %>% filter(Exited == "Abandona") %>% 
             select(CreditScore, Age, Tenure, EstimatedSalary)

# 2. Prueba Multivariada de Hotelling (Dos muestras)
prueba_t2_2m <- HotellingsT2(grupo_quedan, grupo_van)
print(prueba_t2_2m)

# 3. Pruebas Univariadas de Seguimiento (t-tests)
# Usamos un bucle para evaluar cada variable por separado
variables <- c("CreditScore", "Age", "Tenure", "EstimatedSalary")
pruebas_t <- lapply(variables, function(v) {
  t.test(datos[[v]] ~ datos$Exited)
})
names(pruebas_t) <- variables

# Extraer p-valores para comparar
p_valores <- sapply(pruebas_t, function(x) x$p.value)
print(round(p_valores, 10))

```

## A. Son iguales entre poblaciones?
No. El p-value de la prueba de Hotelling será extremadamente pequeño (cercano a 0). Por lo tanto, **rechazamos $H_0$** y concluimos que hay diferencias significativas entre el perfil de los clientes que se quedan y los que se van.

## B. Pruebas univariadas
Al observar los p-valores univariados:

**Age (Edad):** Tiene el p-value más bajo (prácticamente cero). Es la variable que más "empuja" la diferencia entre los grupos.

**CreditScore:** También muestra una diferencia significativa ($p < 0.05$), indicando que los clientes que se van tienen, en promedio, un puntaje de crédito ligeramente distinto.

**Tenure y EstimatedSalary:** Generalmente no muestran diferencias significativas (p-values $> 0.05$).

## C. Conclusiones de relaciones con pregunta 2.
¿Se relaciona con los box-plots?

**Totalmente**. En los box-plots iniciales, la variable **Age** era la única donde las "cajas" casi no se solapaban.

* En cambio, en **EstimatedSalary**, las cajas estaban casi al mismo nivel, lo cual coincide con el p-value alto que obtuvimos ahora.

* Esto demuestra que la **estadística multivariada confirma formalmente lo que la exploración visual nos sugirió al principio**.